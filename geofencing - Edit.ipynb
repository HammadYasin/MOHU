{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy.engine import create_engine\n",
    "from sqlalchemy.types import NVARCHAR\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "import sqlalchemy\n",
    "import geopandas as gpd\n",
    "from shapely.wkt import loads as wkt_loads\n",
    "from shapely.geometry import Point\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import WKT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_wkt = sqlalchemy.create_engine(\n",
    "        \"mssql+pyodbc://dataanalytics:HajiSaab_456@10.13.75.13:1433/Analytics\"\n",
    "        \"?driver=ODBC+Driver+17+for+SQL+Server\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_wkt = \"\"\"\n",
    "SELECT * FROM [Analytics].[buses_track].[WKT_Bus_stops]\n",
    "\"\"\"\n",
    "df_wkt = pd.read_sql(q_wkt, con=engine_wkt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engine and Query for Buses Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine1 = sqlalchemy.create_engine(\n",
    "        \"mssql+pyodbc://dataanalytics:HajiSaab_456@10.13.75.13:1433/ELM-DWH\"\n",
    "        \"?driver=ODBC+Driver+17+for+SQL+Server\")\n",
    "engine2 = sqlalchemy.create_engine(\n",
    "        \"mssql+pyodbc://dataanalytics:HajiSaab_456@10.13.75.13:1433/naqaba\"\n",
    "        \"?driver=ODBC+Driver+17+for+SQL+Server\")\n",
    "q1 = \"\"\"\n",
    "SELECT  DISTINCT \n",
    "        bi_plate_no AS bus_plate_no,  \n",
    "        ht_trip_date AS trip_date, \n",
    "        stg_name_ar AS trip_name, \n",
    "        ht_path_id  AS path_id,\n",
    "        nt_nationality_name_ar AS nationality_ar, \n",
    "        nt_nationality_name_la AS nationality_en\n",
    "FROM        [dbo].[hajtafweej.hajj_trips]\n",
    "INNER JOIN  [dbo].[LU_BUSES_INFOS]                  ON ht_bus_ser_no = bi_id\n",
    "INNER JOIN  [dbo].[hajtafweej.hajj_trips_stages]    ON HT_id=hts_ht_id\n",
    "INNER JOIN  [dbo].[hajtafweej.lu_stages]            ON HTS_STG_ID=STG_ID\n",
    "INNER JOIN  [DBO].[hajtafweej.hajj_trips_details]   ON HTD_HT_ID = HT_ID\n",
    "INNER JOIN  [DBO].[HAJ_DATA]                        ON HTD_HD_ID = HD_ID\n",
    "LEFT JOIN   [DBO].[CMD_CENTER_EH_LU_NATIONALITIES]  ON HD_CURRENT_NATIONALITY_ID = NT_ID\n",
    "WHERE       CAST(ht_trip_date AS DATE) = CAST(GETDATE() AS DATE)\n",
    "AND         ht_season = 1445\n",
    "UNION\n",
    "SELECT  DISTINCT \n",
    "        BI_PLATE_NO AS bus_plate_no, \n",
    "        MANIFESTS_CLOSE_DATE AS trip_date, \n",
    "        HFD_AIRPORT_CODE AS trip_name, \n",
    "        CASE WHEN HFD_AIRPORT_CODE = 'JED' THEN 10\n",
    "             WHEN HFD_AIRPORT_CODE = 'MED' THEN 11\n",
    "        ELSE 99 END AS path_id,\n",
    "        nt_nationality_name_ar AS nationality_ar, \n",
    "        nt_nationality_name_la AS nationality_en\n",
    "FROM        DBO.HAJ_DATA\n",
    "LEFT JOIN   DBO.HM_HC_PRE_ARRIVAL_HAJ_DATA_MAP      ON HD_ID = HHPAHDM_HD_ID\n",
    "LEFT JOIN   DBO.HM_HC_PRE_ARRIVAL_DATA              ON HHPAHDM_HHPAD_ID = HHPAD_ID\n",
    "LEFT JOIN   DBO.MANIFEST_DETAILS                    ON MD_HD_ID = HD_ID\n",
    "LEFT JOIN   DBO.MANIFESTS                           ON MD_MANIFEST_ID = MANIFEST_ID\n",
    "LEFT JOIN   DBO.HAJJ_FLIGHTS_DETAILS                ON HHPAD_HFD_ID = HFD_ID\n",
    "INNER JOIN  DBO.LU_AIR_TRANSPORTATION               ON HFD_AT_ID = AT_ID\n",
    "INNER JOIN  DBO.LU_BUSES_INFOS                      ON BI_ID = MANIFEST_BI_ID\n",
    "LEFT JOIN   DBO.CMD_CENTER_EH_LU_NATIONALITIES      ON HD_CURRENT_NATIONALITY_ID = NT_ID\n",
    "WHERE        MANIFESTS_CLOSE_DATE is NOT NULL\n",
    "AND         MANIFEST_STATE != 512\n",
    "AND         HFD_DIRECTION = 'A'\n",
    "AND         HFD_AIRPORT_CODE in ('JED', 'MED')\n",
    "AND         CAST(HFD_FLIGHT_DATE AS DATE) = CAST(GETDATE() AS DATE)\n",
    "AND         CAST(MANIFESTS_CLOSE_DATE AS DATE) = CAST(GETDATE() AS DATE)\n",
    "\n",
    "\"\"\"\n",
    "q2 = \"\"\"\n",
    "WITH temp AS(\n",
    "SELECT  MAX(CAST(fetchTime AS DATETIME)) as max_dt\n",
    "from naqaba.dbo.naqabalivelocations\n",
    ")\n",
    "SELECT  fetchTime, busLicense, long, lati, speed,\n",
    "        bus_category_name_la, bus_category_name_ar, bus_plate_no, bus_is_active, bus_id, tc_name_ar, manufacturer_name_ar, \n",
    "        season_id, bus_model, bus_type_name_ar, tc_id, bus_plate_la, bus_seats\n",
    "        --bi_naqaba_bus_id\n",
    "FROM        naqaba.dbo.naqabalivelocations\n",
    "INNER JOIN   naqaba.dbo.buses                            ON bus_id = busId\n",
    "WHERE       CAST(fetchTime AS DATETIME) = (SELECT max_dt FROM temp)\n",
    "AND         season_id = 1445\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engine to Push Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_push = sqlalchemy.create_engine(\n",
    "        \"mssql+pyodbc://dataanalytics:HajiSaab_456@10.13.75.13:1433/Analytics\"\n",
    "        \"?driver=ODBC+Driver+17+for+SQL+Server\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bus_stops = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Check Intersecting Polygon with In/Out Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_polygon_intersections(df_wkt, df):\n",
    "    polygons = {}\n",
    "    polygon_intersecting_points = {}\n",
    "\n",
    "    for _, row in df_wkt.iterrows():\n",
    "        base_name = row['KML_File']\n",
    "        polygon_geom = wkt_loads(row['WKT'])\n",
    "        polygon_gdf = gpd.GeoDataFrame(geometry=[polygon_geom], crs='EPSG:4326')\n",
    "        polygons[base_name] = polygon_gdf\n",
    "        polygon_intersecting_points[base_name] = 0\n",
    "\n",
    "    all_polygons_gdf = gpd.GeoDataFrame(pd.concat(polygons.values(), ignore_index=True), crs='EPSG:4326')\n",
    "    all_polygons_gdf['KML_File'] = [name for name, gdf in polygons.items() for _ in range(len(gdf))]\n",
    "    spatial_index = all_polygons_gdf.sindex\n",
    "\n",
    "    df['geometry'] = [Point(x, y) for x, y in zip(df['lati'], df['long'])]\n",
    "    geo_locations = gpd.GeoDataFrame(df, crs='EPSG:4326')\n",
    "\n",
    "    geo_locations['polygon_name'] = ''\n",
    "    geo_locations['location'] = ''\n",
    "    geo_locations['timestamp_in']=''\n",
    "    geo_locations['timestamp_out']=''\n",
    "    if 'time_hours' not in geo_locations.columns:\n",
    "        geo_locations['time_hours'] = 0\n",
    "\n",
    "    for i, point in geo_locations.iterrows():\n",
    "        possible_matches_index = list(spatial_index.intersection(point['geometry'].bounds))\n",
    "        possible_matches = all_polygons_gdf.iloc[possible_matches_index]\n",
    "        intersecting_polygons = possible_matches[possible_matches.intersects(point['geometry'])]\n",
    "        intersecting_names = [name for name in intersecting_polygons['KML_File'].tolist() if name is not None]\n",
    "        if intersecting_names:\n",
    "            geo_locations.at[i, 'polygon_name'] = ', '.join(intersecting_names)\n",
    "            geo_locations.at[i, 'location'] = 'Inside'\n",
    "            geo_locations.at[i, 'timestamp_in']=dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            geo_locations.at[i, 'time_hours'] += geo_locations.at[i, 'time_hours']\n",
    "        else:\n",
    "            geo_locations.at[i, 'polygon_name'] = ''\n",
    "            geo_locations.at[i, 'location'] = 'Outside'\n",
    "            geo_locations.at[i, 'timestamp_out']=dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            geo_locations.at[i, 'time_hours'] += geo_locations.at[i, 'time_hours']\n",
    "\n",
    "    for names in geo_locations['polygon_name'].str.split(', '):\n",
    "        for name in names:\n",
    "            if name and name in polygon_intersecting_points:\n",
    "                polygon_intersecting_points[name] += 1\n",
    "    geo_locations['timestamp_in'] = pd.to_datetime(geo_locations['timestamp_in'])\n",
    "    geo_locations['timestamp_out'] = pd.to_datetime(geo_locations['timestamp_out'])\n",
    "    geo_locations['time_hours']=geo_locations['time_hours'].astype('float64')\n",
    "    return geo_locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Load Data, Function to update data to get total stop times and seperate stops times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df_ELM = pd.read_sql(q1, con=engine1)\n",
    "    bus_data = pd.read_sql(q2, con=engine2)\n",
    "    bus_data = bus_data.merge(df_ELM[['bus_plate_no', 'trip_name']], on='bus_plate_no', how='left')\n",
    "    column = 'trip_name'\n",
    "    bus_data = bus_data.dropna(subset=[column])\n",
    "    bus_data = bus_data[['bus_plate_no','lati','long','trip_name']]\n",
    "    bus_data = calculate_polygon_intersections(df_wkt,bus_data)\n",
    "    ################ Testing with Mock Data #############################\n",
    "    # engine = sqlalchemy.create_engine(\n",
    "    #     \"mssql+pyodbc://dataanalytics:HajiSaab_456@10.13.75.13:1433/Analytics\"\n",
    "    #     \"?driver=ODBC+Driver+17+for+SQL+Server\")\n",
    "    # q = \"\"\"\n",
    "    # SELECT *FROM [Analytics].[buses_track].[test]\n",
    "    # \"\"\"\n",
    "    # bus_data = pd.read_sql(q, con=engine)\n",
    "    # bus_data = calculate_polygon_intersections(df_wkt,bus_data)\n",
    "    #####################################################################\n",
    "    bus_data['geometry'] = bus_data['geometry'].astype(str)\n",
    "    return bus_data\n",
    "\n",
    "def update_dataframe(old_df, new_df):\n",
    "    global df_bus_stops\n",
    "    updated_df = old_df.copy()\n",
    "    for index, row in new_df.iterrows():\n",
    "        bus_plate_no = row['bus_plate_no']\n",
    "        new_location = row['location']\n",
    "        new_polygon =row['polygon_name']\n",
    "        new_timestamp_in =row['timestamp_in']\n",
    "        new_timestamp_out =row['timestamp_out']\n",
    "        new_time_hours = row['time_hours']\n",
    "        new_geometry = row['geometry']\n",
    "\n",
    "        if bus_plate_no in updated_df['bus_plate_no'].values:\n",
    "            old_row = updated_df[updated_df['bus_plate_no'] == bus_plate_no]\n",
    "            old_location = old_row['location'].values[0]\n",
    "            old_timestamp_in=old_row['timestamp_in'].values[0]\n",
    "            old_time_hours = old_row['time_hours'].values[0]\n",
    "            old_polygon = old_row['polygon_name'].values[0]\n",
    "\n",
    "            if old_location != new_location:\n",
    "                updated_df.loc[updated_df['bus_plate_no'] == bus_plate_no, 'location'] = new_location\n",
    "                updated_df.loc[updated_df['bus_plate_no'] == bus_plate_no, 'polygon_name'] = new_polygon\n",
    "                updated_df.loc[updated_df['bus_plate_no'] == bus_plate_no, 'timestamp_in'] = new_timestamp_in\n",
    "                updated_df.loc[updated_df['bus_plate_no'] == bus_plate_no, 'timestamp_out'] = new_timestamp_out\n",
    "                updated_df.loc[updated_df['bus_plate_no'] == bus_plate_no, 'geometry'] = new_geometry\n",
    "                time_delta = new_timestamp_out - old_timestamp_in\n",
    "                new_time_hours += time_delta.total_seconds() / 3600\n",
    "                if pd.isnull(new_time_hours):\n",
    "                    updated_df.loc[updated_df['bus_plate_no'] == bus_plate_no, 'time_hours'] == old_time_hours\n",
    "                else:\n",
    "                    updated_df.loc[updated_df['bus_plate_no'] == bus_plate_no, 'time_hours'] += new_time_hours\n",
    "                # Appending each row to get seprate times spent in each stop\n",
    "                if old_location=='Inside' and new_time_hours!=0 and new_location=='Outside':\n",
    "                    new_row = pd.DataFrame({'bus_plate_no': [bus_plate_no], 'location': [new_location],'polygon':[old_polygon],'time_hours':[new_time_hours]})\n",
    "                    df_bus_stops = pd.concat([df_bus_stops, new_row], ignore_index=True)\n",
    "\n",
    "        else:\n",
    "            updated_df = pd.concat([updated_df, pd.DataFrame([row])], ignore_index=True)\n",
    "    \n",
    "    return updated_df\n",
    "\n",
    "\n",
    "initial_df = load_data()\n",
    "saved_df = initial_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bus Stops will be pushed on the next run !\n",
      "2024-06-15 20:05:49\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m     df_bus_stops \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(dt\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m---> 15\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m300\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    new_df = load_data()\n",
    "    saved_df = update_dataframe(saved_df, new_df)\n",
    "    saved_df['date_latest']=datetime.now().strftime('%m-%d-%Y')\n",
    "    txt_cols=saved_df.select_dtypes(include = ['object']).columns\n",
    "    saved_df.to_sql('live_buses',engine_push, schema='buses_track',if_exists=\"replace\",index=False,dtype={col_name: NVARCHAR for col_name in txt_cols})\n",
    "    if df_bus_stops.empty:\n",
    "        print('Bus Stops will be pushed on the next run !')\n",
    "    else:\n",
    "        df_bus_stops['date_latest']=datetime.now().strftime('%m-%d-%Y')\n",
    "        txt_cols=df_bus_stops.select_dtypes(include = ['object']).columns\n",
    "        df_bus_stops.to_sql('live_buses_stops',engine_push, schema='buses_track',if_exists=\"append\",index=False,dtype={col_name: NVARCHAR for col_name in txt_cols})\n",
    "        df_bus_stops = pd.DataFrame()\n",
    "    print(dt.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    time.sleep(300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
